#include "vmlinux.h"
#include <bpf/bpf_helpers.h>
#include <bpf/bpf_tracing.h>
#include <bpf/bpf_core_read.h>


// struct {
//     __uint(type, BPF_MAP_TYPE_HASH);
//     __uint(max_entries, 40960);
//     __type(key, u64); // addr
//     __type(value, u32); // order of pages
// } page_orders SEC(".maps");

struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 200);
    __type(key, u32); // quarantined flag
    __type(value, u32); 
} alloc_flag SEC(".maps");

struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 40960);
    __type(key, u64); // start addr
    __type(value, u64); // end addr
} page_addr SEC(".maps");


struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 200);
    __type(key, u32); // pid
    __type(value, struct pt_regs); 
} checkpoints SEC(".maps");

// the buffer of this vulnerability is page, 
// its allocation is a little hard to find, 
// but its free is very hard to find

// so, we try to collect every page allocation & free, 
// because we have tested on kmalloc, such operations won't hurt performance in most cases.
#define PAGE_SHIFT	12
#define PAGE_OFFSET 0xffff888000000000
#define vmemmap 0xffffea0000000000
#define __va(x)			((void *)((unsigned long)(x)+PAGE_OFFSET))
#define pfn_to_virt(pfn)	__va((pfn) << PAGE_SHIFT)
#define page_to_pfn(page)	(((page) - vmemmap) / 64)
// #define PFN_PHYS(x)	((x) << PAGE_SHIFT)
#define page_to_virt(x)	pfn_to_virt(page_to_pfn(x))



#define RBTREE_ADD    0
#define RBTREE_DEL    1
#define RBTREE_FIND   2
#define RBTREE_CLR    3





// bool skb_page_frag_refill(unsigned int sz, struct page_frag *pfrag, gfp_t gfp)
// ...
// 2623 		pfrag->page = alloc_pages((gfp & ~__GFP_DIRECT_RECLAIM) |
// ...
// 2633        pfrag->page = alloc_page(gfp);

// ffffffff81a11ad0 <skb_page_frag_refill>:
// ...
// ffffffff81a11b29:       be 03 00 00 00          mov    $0x3,%esi
// ffffffff81a11b2e:       81 e7 ff db fa ff       and    $0xfffadbff,%edi
// ffffffff81a11b34:       81 cf 00 20 05 00       or     $0x52000,%edi
// ffffffff81a11b3a:       e8 a1 d6 8b ff          call   ffffffff812cf1e0 <alloc_pages>   ffffffff81a11b3b: R_X86_64_PLT32        alloc_pages-0x4
// ffffffff81a11b3f:       48 89 03                mov    %rax,(%rbx)
// ...
// ffffffff81a11b56:       31 f6                   xor    %esi,%esi
// ffffffff81a11b58:       89 ef                   mov    %ebp,%edi
// ffffffff81a11b5a:       e8 81 d6 8b ff          call   ffffffff812cf1e0 <alloc_pages>   ffffffff81a11b5b: R_X86_64_PLT32        alloc_pages-0x4
// ffffffff81a11b5f:       48 89 03                mov    %rax,(%rbx)



// ffffffff81a0b3a0 <skb_page_frag_refill>:
// ...
// ffffffff81a0b3fb:       be 03 00 00 00          mov    $0x3,%esi
// ffffffff81a0b400:       81 e7 ff db fa ff       and    $0xfffadbff,%edi
// ffffffff81a0b406:       81 cf 00 20 05 00       or     $0x52000,%edi
// ffffffff81a0b40c:       e8 7f 7c 8f ff          call   ffffffff81303090 <alloc_pages>   ffffffff81a0b40d: R_X86_64_PLT32        alloc_pages-0x4
// ffffffff81a0b411:       48 89 03                mov    %rax,(%rbx)

// python3 -c 'print(hex(0xffffffff81a11b3a-0xffffffff81a11ad0))'
// python3 -c 'print(hex(0xffffffff81a11b5a-0xffffffff81a11ad0))'
// SEC("kprobe/skb_page_frag_refill+0x6a")
// SEC("kprobe/skb_page_frag_refill+0x8a")
// int BPF_KPROBE(prog2)
// {
//     u32 pid = bpf_get_current_pid_tgid();
//     u32 order = ctx->si;
//     u32 val = (u32) (1 << order);
//     int err = bpf_map_update_elem(&alloc_flag, &pid, &val, BPF_ANY);
//     if (err < 0) {
//         bpf_printk("skb_page_frag_refill alloc failed\n");
//     }

//     return 0;
// }


// python3 -c 'print(hex(0xffffffff81a11b3f-0xffffffff81a11ad0))'
// python3 -c 'print(hex(0xffffffff81a11b5f-0xffffffff81a11ad0))'

// SEC("kprobe/skb_page_frag_refill+0x6f")
// SEC("kprobe/skb_page_frag_refill+0x8f")
// int BPF_KPROBE(prog3)
// {
//     u32 pid = bpf_get_current_pid_tgid();
//     u32 *pval = bpf_map_lookup_elem(&alloc_flag, &pid);
//     int err = 0;
//     if (pval) {
//         u32 pages = *pval;
//         u64 start_addr = (u64)page_to_virt(ctx->ax);
//         u64 end_addr = start_addr + (pages * 0x1000);
//         bpf_printk("skb_page_frag_refill range [%lx, %lx), %d pages\n", start_addr, end_addr, pages);
//         bpf_map_delete_elem(&alloc_flag, &pid);
//         bpf_map_update_elem(&page_addr, &start_addr, &end_addr, BPF_ANY);
        // for (u32 i = 0;i <= 100;i++) {
        //     u64 addr = start_addr + i * 0x1000;
        //     if (addr <= end_addr) {
        //         bpf_printk("\tskb_page_frag_refill put %lx page\n", addr);
        //         err = bpf_map_update_elem(&page_addr, &start_addr, &end_addr, BPF_ANY);
        //         if (err < 0) {
        //             bpf_printk("tp_alloc update failed %d\n", err);
        //         }
        //     } else {
        //         break;
        //     }
        // }
//     }
//     return 0;
// }


// some overhead is too large, test smaller ones
// SEC("tracepoint/kmem/mm_page_alloc")
// int tp_alloc(struct trace_event_raw_mm_page_alloc *ctx)
// {
//     u64 key = (u64)pfn_to_virt(ctx->pfn);
//     u32 val = (u32)ctx->order;
//     u64 end_addr = key + (1 << val) * 0x1000;
//     int err = 0;

//     for (u32 i = 0;i < 100;i++) {
//         u64 start_addr = key + i * 0x1000;
//         if (start_addr <= end_addr) {
//             err = bpf_map_update_elem(&page_addr, &start_addr, &end_addr, BPF_ANY);
//             if (err < 0) {
//                 bpf_printk("tp_alloc update failed %d\n", err);
//             }
//         } else {
//             break;
//         }
//     }

//     return 0;
// }


// real free 
// static void __sk_destruct(struct rcu_head *head)
// ...
// 	if (sk->sk_frag.page) {
// 		put_page(sk->sk_frag.page);  here free the sk_frag pages.
// 		sk->sk_frag.page = NULL;
// 	}


// SEC("tracepoint/kmem/mm_page_free")
// int tp_free(struct trace_event_raw_mm_page_free* ctx)
// {
//     u64 key = (u64)pfn_to_virt(ctx->pfn);
//     int err = 0;
//     u64 *pval = bpf_map_lookup_elem(&page_addr, &key);

//     if (pval) {
//         err = bpf_map_delete_elem(&page_addr, &key);
//         u64 end_addr = *pval;
//         bpf_printk("page_free range [%lx, %lx)\n", key, end_addr);
//         for (u32 i = 0;i < 100;i++) {
//             u64 start_addr = key + i * 0x1000;
//             if (start_addr <= end_addr) {
//                 bpf_printk("\tpage remove %lx page\n", start_addr);
//                 err = bpf_map_delete_elem(&page_addr, &start_addr);
//                 if (err < 0) {

//                 }
//             } else {
//                 break;
//             }
//         }
//     }
//     return 0;
// }


// checkpoint
SEC("kprobe/null_skcipher_crypt")
int BPF_KPROBE(prog0)
{
    u32 pid = bpf_get_current_pid_tgid();
    struct pt_regs x_regs = {};
	x_regs.r15 = ctx->r15 ;
	x_regs.r14 = ctx->r14 ;
	x_regs.r13 = ctx->r13 ;
	x_regs.r12 = ctx->r12 ;
	x_regs.bp  = ctx->bp  ;
	x_regs.bx  = ctx->bx  ;
	x_regs.r11 = ctx->r11;
	x_regs.r10 = ctx->r10;
	x_regs.r9  = ctx->r9 ;
	x_regs.r8  = ctx->r8 ;
	x_regs.ax  = ctx->ax ;
	x_regs.cx  = ctx->cx ;
	x_regs.dx  = ctx->dx ;
	x_regs.si  = ctx->si ;
	x_regs.di  = ctx->di ;
    x_regs.orig_ax = ctx->orig_ax;
	x_regs.ip = ctx->ip;
	x_regs.cs = ctx->cs;
	x_regs.flags = ctx->flags;
	x_regs.sp = ctx->sp;
	x_regs.ss = ctx->ss;
    // bpf_printk("checkpoint setup pid:%u\n", pid);
    int err = bpf_map_update_elem(&checkpoints, &pid, &x_regs, BPF_ANY);
    if (err < 0) {
        bpf_printk("checkpoint setup failed: %d\n", err);
        return err;
    }
    return 0;
}

SEC("kretprobe/null_skcipher_crypt")
int BPF_KRETPROBE(prog10)
{
    u32 pid = bpf_get_current_pid_tgid();
    struct pt_regs* pregs = bpf_map_lookup_elem(&checkpoints, &pid);
    if (pregs) {
        int err = bpf_map_delete_elem(&checkpoints, &pid);
        // bpf_printk("checkpoint remove pid:%u\n", pid);
        if (err < 0) {
            bpf_printk("checkpoints delete failed:%d\n", err);
            return err;
        }
    }
    return 0;
}



//76 static int null_skcipher_crypt(struct skcipher_request *req)
// {
// 	struct skcipher_walk walk;
// 	int err;

// 	err = skcipher_walk_virt(&walk, req, false);

// 83	while (walk.nbytes) {
// 84		if (walk.src.virt.addr != walk.dst.virt.addr) {
// 85			memcpy(walk.dst.virt.addr, walk.src.virt.addr,
// 86			       walk.nbytes);
// 87			// pr_info("null_skcipher_crypt: dst:%016lx, len:0x%x\n", (unsigned long)walk.dst.virt.addr, walk.nbytes);
// 88		}
// 89		err = skcipher_walk_done(&walk, 0);
// 	}
// 	return err;
// }

// https://github.com/torvalds/linux/commit/fa40d9734a57bcbfa79a280189799f76c88f7bb0

// ffffffff814ead30 <null_skcipher_crypt>:
// ...
// ffffffff814ead6c:       48 8b 74 24 08          mov    0x8(%rsp),%rsi
// ffffffff814ead71:       48 8b 7c 24 18          mov    0x18(%rsp),%rdi
// ffffffff814ead76:       48 39 fe                cmp    %rdi,%rsi
// ffffffff814ead79:       74 05                   je     ffffffff814ead80 <null_skcipher_crypt+0x50>
// ffffffff814ead7b:       e8 80 3d 8a 00          call   ffffffff81d8eb00 <__memcpy>


// ffffffff814f2770 <null_skcipher_crypt>:
// ...
// ffffffff814f279f:       e8 5c aa ff ff          call   ffffffff814ed200 <skcipher_walk_virt>    ffffffff814f27a0: R_X86_64_PLT32        skcipher_walk_virt-0x4
// ffffffff814f27a4:       8b 54 24 30             mov    0x30(%rsp),%edx
// ffffffff814f27a8:       85 d2                   test   %edx,%edx
// ffffffff814f27aa:       74 26                   je     ffffffff814f27d2 <null_skcipher_crypt+0x62>
// ffffffff814f27ac:       48 8b 74 24 08          mov    0x8(%rsp),%rsi
// ffffffff814f27b1:       48 8b 7c 24 18          mov    0x18(%rsp),%rdi
// ffffffff814f27b6:       48 39 fe                cmp    %rdi,%rsi
// ffffffff814f27b9:       74 05                   je     ffffffff814f27c0 <null_skcipher_crypt+0x50>
// ffffffff814f27bb:       e8 70 86 8f 00          call   ffffffff81deae30 <__memcpy>      ffffffff814f27bc: R_X86_64_PLT32        memcpy-0x4
// ffffffff814f27c0:       31 f6                   xor    %esi,%esi
// ffffffff814f27c2:       48 89 e7                mov    %rsp,%rdi
// ffffffff814f27c5:       e8 a6 a0 ff ff          call   ffffffff814ec870 <skcipher_walk_done>    ffffffff814f27c6: R_X86_64_PLT32        skcipher_walk_done-0x4
// ffffffff814f27ca:       8b 54 24 30             mov    0x30(%rsp),%edx



// python -c 'print(hex(0xffffffff814ead7b-0xffffffff814ead30))'
// python -c 'print(hex(0xffffffff814ee31b-0xffffffff814ee2d0))'
// python -c 'print(hex(0xffffffff814f27bb- 0xffffffff814f2770 ))'
// walk: rsp + 0
// walk.dst.virt.addr: walk + 24
// walk.nbytes: walk + 48
SEC("kprobe/null_skcipher_crypt+0x4b")
int BPF_KPROBE(prog1)
{
    // check len
    u64 walk_dst_virt_addr = ctx->di;
    u64 walk_src_virt_addr = ctx->si;
    u32 walk_nbytes = ctx->dx;
    u32 walk_total = 0;
    u64 walk_total_addr = ctx->sp + 72;
    bpf_core_read(&walk_total, 4, walk_total_addr);

    u64 buff_addr = bpf_get_slab_start(walk_dst_virt_addr);
    u64 buff_len = bpf_get_buff_len(walk_dst_virt_addr);
    // bpf_printk("%lx:%lx:%lx\n", walk_dst_virt_addr, buff_addr, buff_len);
    // bpf_printk("null_skcipher_crypt %lx, %lx, %x\n", walk_dst_virt_addr, walk_nbytes, walk_total);

    u64 buff = (buff_addr + buff_len);
    u64 memcpy_dst = (walk_dst_virt_addr + walk_total);

    // bpf_printk("output: %lx, %lx\n", buff, memcpy_dst);

    u64 oob = buff < memcpy_dst;
    if (oob == 1) {
        bpf_printk("null_skcipher_crypt:oob\n");
        int err = bpf_send_signal(9);// SIGKILL
        bpf_printk("bpf send kill signal: %d\n", err);
        if (err < 0) {
            bpf_printk("null_skcipher_crypt sendsignal failed:%d\n", err);
            return err;
        }
        u32 pid = bpf_get_current_pid_tgid();
        struct pt_regs *px_regs = bpf_map_lookup_elem(&checkpoints, &pid);
        if (px_regs) {
            px_regs->ax = (unsigned long)((int)-35);
            px_regs->ip = 0xffffffff814f27e6;
            err = bpf_set_regs(ctx, px_regs);
            bpf_printk("null_skcipher_crypt bpf_set_regs: %d\n", err);
        }
    }
    
    // if (porder) {
    //     bpf_printk("null_skcipher_crypt find dst: [0x%lx, 0x%lx)\n", walk_dst_virt_addr, *porder);
    //     u64 endaddr = walk_dst_virt_addr + walk_nbytes;
    //     int oob = (endaddr > *porder);
    //     bpf_printk("null_skcipher_crypt memcpy  : [0x%lx, 0x%lx)  OOB:%d\n", walk_dst_virt_addr, endaddr, oob);
    //     // if (oob == 1) {
    //         int err = bpf_send_signal(9);// SIGKILL
    //         bpf_printk("bpf send kill signal: %d\n", err);
    //         if (err < 0) {
    //             bpf_printk("null_skcipher_crypt sendsignal failed:%d\n", err);
    //             return err;
    //         }
    //         u32 pid = bpf_get_current_pid_tgid();
    //         struct pt_regs *px_regs = bpf_map_lookup_elem(&checkpoints, &pid);
    //         if (px_regs) {
    //             px_regs->ax = (unsigned long)((int)-35);
    //             px_regs->ip = 0xffffffff814f2776;
    //             err = bpf_set_regs(ctx, px_regs);
    //             bpf_printk("null_skcipher_crypt bpf_set_regs: %d\n", err);
    //         }
    //         // err = bpf_set_regs(ctx, 0, -35);
    //         // bpf_printk("bpf set rax: %d\n", err);
    //         // err = bpf_set_regs(ctx, 1, 0xffffffff814f26c6);
    //         // bpf_printk("bpf set rip: %d\n", err);
    //         // int err = bpf_send_signal(11);//SIGSEGV	
    //         // bpf_override_return(ctx, 0);
            
    //     // }
        
    // }
    return 0;
}





char LICENSE[] SEC("license") = "Dual BSD/GPL";
